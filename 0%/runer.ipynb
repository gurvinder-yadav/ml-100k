{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import sklearn.metrics as skm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "ratings = ['cosineRatings.csv',\r\n",
    "            'jaccardRatings.csv',\r\n",
    "            'pearsonRatings.csv',\r\n",
    "            'pipRatings.csv',\r\n",
    "            'mpipRatings1.csv'\r\n",
    "            ]\r\n",
    "f1_score,mae,recall,precision,rmse = np.zeros(5),np.zeros(5),np.zeros(5),np.zeros(5),np.zeros(5)\r\n",
    "measures = ['Cosine',\r\n",
    "            'Jaccard',\r\n",
    "            'Pearson',\r\n",
    "            'PIP',\r\n",
    "            'MPIP']\r\n",
    "count = 0\r\n",
    "for i in ratings:\r\n",
    "    sim = pd.read_csv(i).to_numpy().transpose()\r\n",
    "    # print(i)\r\n",
    "    mae[count] = skm.mean_absolute_error(sim[2],sim[3])\r\n",
    "    rmse[count] = skm.mean_squared_error(sim[2],sim[3],squared=False)\r\n",
    "    f1_score[count] = skm.f1_score(sim[2],sim[3],average='weighted')\r\n",
    "    precision[count] = skm.precision_score(sim[2],sim[3],average='weighted')\r\n",
    "    recall[count] =skm.recall_score(sim[2],sim[3],average='weighted')\r\n",
    "    # print(count)\r\n",
    "    count+=1\r\n",
    "errors = pd.DataFrame({'MAE':mae,\r\n",
    "                        'RMSE':rmse,\r\n",
    "                        'Precision':precision,\r\n",
    "                        'Recall':recall,\r\n",
    "                        'f1-score':f1_score\r\n",
    "                        })\r\n",
    "errors.index = measures\r\n",
    "errors"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\gurvi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\gurvi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\gurvi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\gurvi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\gurvi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              MAE      RMSE  Precision    Recall  f1-score\n",
       "Cosine   0.673892  0.862879   0.381715  0.360336  0.254384\n",
       "Jaccard  0.696563  0.872077   0.136358  0.335222  0.185118\n",
       "Pearson  0.454610  0.722561   0.421700  0.574524  0.432734\n",
       "PIP      0.445074  0.714438   0.339842  0.582960  0.429376\n",
       "MPIP     0.362855  0.628035   0.665635  0.650363  0.564115"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cosine</th>\n",
       "      <td>0.673892</td>\n",
       "      <td>0.862879</td>\n",
       "      <td>0.381715</td>\n",
       "      <td>0.360336</td>\n",
       "      <td>0.254384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jaccard</th>\n",
       "      <td>0.696563</td>\n",
       "      <td>0.872077</td>\n",
       "      <td>0.136358</td>\n",
       "      <td>0.335222</td>\n",
       "      <td>0.185118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pearson</th>\n",
       "      <td>0.454610</td>\n",
       "      <td>0.722561</td>\n",
       "      <td>0.421700</td>\n",
       "      <td>0.574524</td>\n",
       "      <td>0.432734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIP</th>\n",
       "      <td>0.445074</td>\n",
       "      <td>0.714438</td>\n",
       "      <td>0.339842</td>\n",
       "      <td>0.582960</td>\n",
       "      <td>0.429376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MPIP</th>\n",
       "      <td>0.362855</td>\n",
       "      <td>0.628035</td>\n",
       "      <td>0.665635</td>\n",
       "      <td>0.650363</td>\n",
       "      <td>0.564115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# t = pd.read_csv('rating predictions.csv')\r\n",
    "# jac = t.pop('jaccard').astype(int)\r\n",
    "# test = pd.read_csv('test.csv')\r\n",
    "# frames = [test,jac]\r\n",
    "# new = pd.concat(frames,axis=1)\r\n",
    "# new.to_csv('jaccardRatings.csv',sep=',',index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3de2d02b11921545bf1816bc45552ddc366ed99bb60e73ad62fb9cbd6f53e5b0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}