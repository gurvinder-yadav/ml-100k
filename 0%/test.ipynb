{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "# import sklearn.model_selection as sks\r\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\r\n",
    "# from scipy.stats import pearsonr\r\n",
    "import sklearn.metrics as skm\r\n",
    "# from time import time"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# data = pd.read_csv('100K_mean_dataset.csv',delimiter='\\t',names=['iId','uId','rating'])\r\n",
    "# train,test = sks.train_test_split(data,test_size=0.2)\r\n",
    "# train.to_csv('train.csv',sep=',',index=False)\r\n",
    "# test.to_csv('test.csv',sep=',',index=False)\r\n",
    "# train,test = train.sort_values(['uId','iId']),test.sort_values(['uId','iId'])\r\n",
    "# train['rating'],test['rating'] = round(train['rating'],0),round(test['rating'],0)\r\n",
    "# Ntrain ,Ntest = train.to_numpy(dtype=int),test.to_numpy(dtype=int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\r\n",
    "# matrix = np.zeros((943,1682),dtype=int)\r\n",
    "# for i in Ntrain:\r\n",
    "#     matrix[i[1]-1,i[0]-1] = i[2]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# cosine = cosine_similarity(matrix)\r\n",
    "# pearson = np.zeros((943,943))\r\n",
    "# jaccard = np.zeros((943,943))\r\n",
    "# for i in range(len(matrix)):\r\n",
    "#     for j in range(len(matrix)):\r\n",
    "#         pearson[i,j] = pearsonr(matrix[i],matrix[j])[0]\r\n",
    "#         jaccard[i,j] = skm.jaccard_score(matrix[i],matrix[j],average='weighted')\r\n",
    "\r\n",
    "# pd.DataFrame(cosine).to_csv('cosine.csv',sep=',',index=False)\r\n",
    "# pd.DataFrame(pearson).to_csv('pearson.csv',sep=',',index=False)\r\n",
    "# pd.DataFrame(jaccard).to_csv('jaccard.csv',sep=',',index=False)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "cosine = pd.read_csv('cosine.csv').to_numpy()\r\n",
    "pearson = pd.read_csv('pearson.csv').to_numpy()\r\n",
    "jaccard = pd.read_csv('jaccard.csv').to_numpy()\r\n",
    "pip = pd.read_csv('pip.csv').to_numpy()\r\n",
    "mpip = pd.read_csv('mpip.csv').to_numpy()\r\n",
    "train = pd.read_csv('train.csv').to_numpy()\r\n",
    "test = pd.read_csv('test.csv').to_numpy()\r\n",
    "matrix = np.zeros((943,1682),dtype=int)\r\n",
    "for row in train:\r\n",
    "    matrix[int(row[1])-1,int(row[0])-1] = row[2]\r\n",
    "    \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# Rm = 3\r\n",
    "# Rmin = 1\r\n",
    "# Rmax = 5\r\n",
    "# def Agreement(r1,r2):\r\n",
    "#     if ((r1>Rm and r2<Rm) or (r1<Rm or r2<Rm)):\r\n",
    "#         return True\r\n",
    "#     else :\r\n",
    "#         return False\r\n",
    "# def Distance(r1,r2):\r\n",
    "#     if Agreement(r1,r2):\r\n",
    "#         return abs(r1-r2)\r\n",
    "#     else:\r\n",
    "#         return 2*(abs(r1-r2))\r\n",
    "# def Proximity(r1,r2):\r\n",
    "#     return ((2*(Rmax-Rmin)+1)-Distance(r1,r2))**2\r\n",
    "# def Impact(r1,r2):\r\n",
    "#     result = (abs(r1-Rm)+1)*(abs(r2-Rm)+1)\r\n",
    "#     if Agreement(r1,r2):\r\n",
    "#         return result\r\n",
    "#     elif not(Agreement(r1,r2)) and result!=0:\r\n",
    "#         return 1/result\r\n",
    "# def AvgRating(item):\r\n",
    "#     sum = matrix[:,item].sum()\r\n",
    "#     n = np.count_nonzero(matrix[:,item])\r\n",
    "#     return sum/n\r\n",
    "# def Popularity(r1,r2,uk):\r\n",
    "#     if (r1>uk and r2>uk) or (r1<uk or r2<uk):\r\n",
    "#         return (1+(((r1+r2)/2)-uk)**2)\r\n",
    "#     else:\r\n",
    "#         return 1\r\n",
    "# def PIP(r1,r2,item):\r\n",
    "#     Rm = 3\r\n",
    "#     Rmin = 1\r\n",
    "#     Rmax = 5\r\n",
    "#     proximity = Proximity(r1,r2)\r\n",
    "#     impact = Impact(r1,r2)\r\n",
    "#     item_avg= AvgRating(item)\r\n",
    "#     popularity = Popularity(r1,r2,item_avg)\r\n",
    "#     return proximity*impact*popularity\r\n",
    "# def agPIP(u1,u2,matrix):\r\n",
    "#     sum=0\r\n",
    "#     for i in range(1682):\r\n",
    "#         sum+=PIP(matrix[u1,i],matrix[u2,i],i)\r\n",
    "#     return sum\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# %time agPIP(1,1,matrix)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# pip = np.zeros((943,943))\r\n",
    "# for i in range(943):\r\n",
    "#     for j in range(943):\r\n",
    "#         if i==j:\r\n",
    "#             pip[i,j] = 3437235\r\n",
    "#             break\r\n",
    "#       #  print(agPIP(i,j,matrix))\r\n",
    "#         pip[i,j] = agPIP(i,j,matrix)\r\n",
    "#         pip[j,i] = pip[i,j]\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# pip_df = pd.DataFrame(pip)\r\n",
    "# pip_df.to_csv('pip.csv',sep=',',index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# def PredRating(user,item,similarity):\r\n",
    "#     try:\r\n",
    "#         top = similarity[user].argsort()[1:100]\r\n",
    "#     except IndexError:\r\n",
    "#         sum,count = 0,0\r\n",
    "#         for j in range(1682):\r\n",
    "#             if matrix[user,j] != 0:\r\n",
    "#                 count+=1\r\n",
    "#                 sum+=1\r\n",
    "#         return sum/count\r\n",
    "#     temp,avgUh,simi = [],[],[]\r\n",
    "#     for i in top:\r\n",
    "#         if matrix[i,item] !=0:\r\n",
    "#             temp.append(i)\r\n",
    "#             simi.append(similarity[user,i])\r\n",
    "#     temp.append(user)\r\n",
    "#     for i in temp:\r\n",
    "#         sum,count = 0,0\r\n",
    "#         for j in range(1682):\r\n",
    "#             if matrix[i,j] != 0:\r\n",
    "#                 count+=1\r\n",
    "#                 sum+=matrix[i,j]\r\n",
    "#         avgUh.append(sum/count)\r\n",
    "#     avgU = np.nan_to_num(np.array(avgUh.pop()))\r\n",
    "#     temp.pop()\r\n",
    "#     if len(temp)==0:\r\n",
    "#         return avgU\r\n",
    "#     simi = np.nan_to_num(np.array(simi))\r\n",
    "#     num = (simi*(avgUh-avgU)).sum()\r\n",
    "#     den = simi.sum()\r\n",
    "#     # for i in range(len(temp)):\r\n",
    "#     #     num+=similarity[user,temp[i]]*avgUh[i]\r\n",
    "#     #     den+=similarity[user,temp[i]]\r\n",
    "#     try:\r\n",
    "#         result = (round((avgU+num/den),0))\r\n",
    "#     except ZeroDivisionError:\r\n",
    "#         result = 0\r\n",
    "#     return result\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# len(test.transpose()[1])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "317226"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "\r\n",
    "# users = test.transpose()[1,:150000]\r\n",
    "# items = test.transpose()[0,:150000]\r\n",
    "# ratings = test.transpose()[2,:150000]\r\n",
    "# cosinePred,jaccardPred,pearsonPred,pipPred,mpipPred = np.zeros(150000),np.zeros(150000),np.zeros(150000),np.zeros(150000),np.zeros(150000)\r\n",
    "# user = np.zeros(150000)\r\n",
    "# item = np.zeros(150000)\r\n",
    "# rating = np.zeros(150000)\r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# for i in range(150000):\r\n",
    "#     jaccardPred[i] = PredRating(int(users[i])-1,int(items[i])-1,jaccard)\r\n",
    "#     pearsonPred[i] = PredRating(int(users[i])-1,int(items[i])-1,pearson)\r\n",
    "#     pipPred[i] = PredRating(int(users[i])-1,int(items[i])-1,pip)\r\n",
    "#     mpipPred[i] = PredRating(int(users[i])-1,int(items[i])-1,mpip)\r\n",
    "#     cosinePred[i] = PredRating(int(users[i])-1,int(items[i])-1,cosine)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# mpip"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# result = pd.DataFrame({'user':users,\r\n",
    "#                         'item':items,\r\n",
    "#                         'rating':ratings,\r\n",
    "#                         'cosine':cosinePred,\r\n",
    "#                         # 'jaccard':jaccardPred,\r\n",
    "#                         'pearson':pearsonPred,\r\n",
    "#                         'pip':pipPred,\r\n",
    "#                         'mpip':mpipPred\r\n",
    "#                         }).fillna(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# result.to_csv('rating predictions.csv',sep=',',index=False)\r\n",
    "# resTrans=result.to_numpy().transpose()\r\n",
    "# f1_score,mae,recall,precision,rmse = np.zeros(5),np.zeros(5),np.zeros(5),np.zeros(5),np.zeros(5)\r\n",
    "# resTrans[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# resTrans[2]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# result.to_csv('result',index=False,sep='\\t')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# import numpy as np\r\n",
    "# import pandas as pd\r\n",
    "# import sklearn.metrics as skm\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# ratings = pd.read_csv('rating predictions.csv',sep=',')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# result['user'] = result['user'].astype(int)\r\n",
    "# result['item'] = result['item'].astype(int)\r\n",
    "# result['rating'] = result['rating'].round(decimals=0).astype(int)\r\n",
    "# result['cosine'] = result['cosine'].astype(int)\r\n",
    "# result['jaccard'] = result['jaccard'].astype(int)\r\n",
    "# result['pearson'] = result['pearson'].astype(int)\r\n",
    "# result['pip'] = result['pip'].astype(int)\r\n",
    "# result['mpip'] = result['mpip'].astype(int)\r\n",
    "# result.to_csv('t0.csv',sep=',',index=False)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# ratings\r\n",
    "# ratings = pd.read_csv('rating predictions.csv',delimiter=',')\r\n",
    "# ratings['user'] = ratings['user'].astype(int)\r\n",
    "# ratings['item'] = ratings['item'].astype(int)\r\n",
    "# ratings['rating'] = ratings['rating'].round(decimals=0)#.astype(int)\r\n",
    "# # ratings['cosine'] = ratings['cosine'].astype(int)\r\n",
    "# # ratings['jaccard'] = ratings['jaccard'].astype(int)\r\n",
    "# # ratings['pearson'] = ratings['pearson'].astype(int)\r\n",
    "# # ratings['pip'] = ratings['pip'].astype(int)\r\n",
    "# # ratings['mpip'] = ratings['mpip'].astype(int)\r\n",
    "df1 = pd.read_csv('t0.csv',delimiter=',')\r\n",
    "df2 = pd.read_csv('t1.csv',delimiter=',')\r\n",
    "result = df1.append(df2)\r\n",
    "result.dropna()\r\n",
    "# ratings"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        user  item  rating  cosine  jaccard  pearson  pip  mpip\n",
       "0        303  1460       3       3        3        3    3     4\n",
       "1        633   660       3       3        3        3    3     3\n",
       "2        502   274       3       3        3        3    3     4\n",
       "3         35   553       3       3        3        3    3     4\n",
       "4        377  1351       4       3        3        3    3     4\n",
       "...      ...   ...     ...     ...      ...      ...  ...   ...\n",
       "149995   472   789       4       3        3        3    3     3\n",
       "149996   689   595       4       3        3        3    3     3\n",
       "149997   775   888       4       3        3        3    3     3\n",
       "149998   932  1377       4       3        3        3    3     3\n",
       "149999   144    29       4       3        3        3    3     4\n",
       "\n",
       "[300000 rows x 8 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>cosine</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>pearson</th>\n",
       "      <th>pip</th>\n",
       "      <th>mpip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>303</td>\n",
       "      <td>1460</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>633</td>\n",
       "      <td>660</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>274</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>553</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>377</td>\n",
       "      <td>1351</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>472</td>\n",
       "      <td>789</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>689</td>\n",
       "      <td>595</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>775</td>\n",
       "      <td>888</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>932</td>\n",
       "      <td>1377</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>144</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 8 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# count = 0\r\n",
    "# resTrans = result.transpose().to_numpy()\r\n",
    "# f1_score,mae,rmse,recall,precision = np.zeros(5,dtype=float),np.zeros(5,dtype=float),np.zeros(5,dtype=float),np.zeros(5,dtype=float),np.zeros(5,dtype=float)\r\n",
    "# for i in [3,4,6,5]:\r\n",
    "#     f1_score[count] = (skm.f1_score(resTrans[2],resTrans[i],average='micro'))\r\n",
    "#     mae[count] = (skm.mean_absolute_error(resTrans[2],resTrans[i]))\r\n",
    "#     rmse[count] = (skm.mean_squared_error(resTrans[2],resTrans[i],squared=False))\r\n",
    "#     recall[count] = (skm.recall_score(resTrans[2],resTrans[i],average='micro'))\r\n",
    "#     precision[count] = (skm.precision_score(resTrans[2],resTrans[i],average='micro'))\r\n",
    "#     count+=1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# errors = pd.DataFrame({'mae':mae,\r\n",
    "#                         'rmse':rmse,\r\n",
    "#                         'precision':precision,\r\n",
    "#                         'recall':recall,\r\n",
    "#                         'f1-score':f1_score\r\n",
    "#                         })\r\n",
    "# errors.index = ['cosine',\r\n",
    "#                 'jaccard',\r\n",
    "#                 'pearson',\r\n",
    "#                 'pip',\r\n",
    "#                 'mpip'\r\n",
    "#                 ]\r\n",
    "# errors"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "              mae      rmse  precision    recall  f1-score\n",
       "cosine   0.664647  0.852944   0.366787  0.366787  0.366787\n",
       "jaccard  0.696450  0.871900   0.335233  0.335233  0.335233\n",
       "pearson  0.664647  0.852944   0.366787  0.366787  0.366787\n",
       "pip      0.664647  0.852944   0.366787  0.366787  0.366787\n",
       "mpip     0.000000  0.000000   0.000000  0.000000  0.000000"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cosine</th>\n",
       "      <td>0.664647</td>\n",
       "      <td>0.852944</td>\n",
       "      <td>0.366787</td>\n",
       "      <td>0.366787</td>\n",
       "      <td>0.366787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaccard</th>\n",
       "      <td>0.696450</td>\n",
       "      <td>0.871900</td>\n",
       "      <td>0.335233</td>\n",
       "      <td>0.335233</td>\n",
       "      <td>0.335233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pearson</th>\n",
       "      <td>0.664647</td>\n",
       "      <td>0.852944</td>\n",
       "      <td>0.366787</td>\n",
       "      <td>0.366787</td>\n",
       "      <td>0.366787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pip</th>\n",
       "      <td>0.664647</td>\n",
       "      <td>0.852944</td>\n",
       "      <td>0.366787</td>\n",
       "      <td>0.366787</td>\n",
       "      <td>0.366787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mpip</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# errors.to_csv('results.csv',sep=',')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "items = pd.read_csv('u.item',delimiter='|',names=[str(i) for i in range(29)],encoding='latin-1')['1'].to_numpy()\r\n",
    "filterwords = pd.read_csv('offensive word.txt').to_numpy()\r\n",
    "def top(user,similarity,matrix,items):\r\n",
    "    topMovies = []\r\n",
    "    simUsers = similarity[user].argsort()[:5]+1\r\n",
    "    topMovies = matrix[simUsers[:]].argsort()[:10]\r\n",
    "    titles = []\r\n",
    "    years = []\r\n",
    "    for i in topMovies:\r\n",
    "        for j in i:\r\n",
    "            itemsTemp = (str(items[j])).split('(')\r\n",
    "            titles.append(itemsTemp[0])\r\n",
    "            years.append(itemsTemp[1].rstrip(')'))\r\n",
    "            if(len(titles)>20):\r\n",
    "              break\r\n",
    "        if(len(titles)>20):\r\n",
    "              break\r\n",
    "    years = np.array(years).argsort()\r\n",
    "    titles = np.array(titles)\r\n",
    "    titles = titles[years[:]]\r\n",
    "    for i in range(len(titles)):\r\n",
    "      temp = str(titles[i]).split()\r\n",
    "      if temp in filterwords:\r\n",
    "        titles.pop(index=i)\r\n",
    "    return titles"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(top(660,cosine,matrix,items))\r\n",
    "print(top(660,jaccard,matrix,items))\r\n",
    "print(top(660,pearson,matrix,items))\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['They Made Me a Criminal ' 'In the Name of the Father ' 'Century '\n",
      " 'Six Degrees of Separation ' 'Drop Zone ' 'Toy Story ' 'Castle Freak '\n",
      " 'Walking Dead, The ' 'Father of the Bride Part II ' 'French Kiss '\n",
      " 'Devil in a Blue Dress ' 'Everyone Says I Love You '\n",
      " 'Love Is All There Is ' 'Spice World ' \"Dante's Peak \" 'Assignment, The '\n",
      " 'Wonderland ' 'Game, The ' 'Deep Rising ' 'Blues Brothers 2000 '\n",
      " 'Umbrellas of Cherbourg, The ']\n",
      "['Penny Serenade ' 'American Werewolf in London, An ' \"Schindler's List \"\n",
      " 'Shopping ' 'Love Affair ' 'Lassie ' 'Kicking and Screaming '\n",
      " \"National Lampoon's Senior Trip \" 'American President, The '\n",
      " 'Grumpier Old Men ' 'Hamlet ' 'Quest, The ' 'Everyone Says I Love You '\n",
      " 'FairyTale: A True Story ' 'As Good As It Gets ' 'Fire Down Below '\n",
      " 'Wishmaster ' 'Wings of the Dove, The ' \"Ulee's Gold \"\n",
      " 'Desperate Measures ' 'Mrs. Brown ']\n",
      "['Penny Serenade ' 'Purple Noon '\n",
      " 'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb '\n",
      " 'Victor/Victoria ' 'Last of the Mohicans, The ' 'Body Snatchers '\n",
      " 'Boys of St. Vincent, The ' 'Angels in the Outfield ' 'Grosse Fatigue '\n",
      " 'Little Odessa ' 'Don Juan DeMarco ' 'Santa with Muscles '\n",
      " 'Line King: Al Hirschfeld, The ' \"Microcosmos: Le peuple de l'herbe \"\n",
      " 'Four Days in September ' 'Air Bud ' \"'Til There Was You \" 'Mimic '\n",
      " 'In the Company of Men ' 'Before the Rain ' 'Star Maker, The ']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print(top(660,pip,matrix,items))\r\n",
    "print(top(660,mpip,matrix,items))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[\"Singin' in the Rain \" 'High Noon ' 'Cape Fear '\n",
      " 'Manchurian Candidate, The ' 'Audrey Rose ' 'Somewhere in Time '\n",
      " 'Conan the Barbarian ' 'Sex, Lies, and Videotape ' 'Enchanted April '\n",
      " 'Philadelphia ' 'Made in America ' 'Perfect World, A ' 'Addiction, The '\n",
      " 'Toy Story ' 'American President, The ' 'Fair Game '\n",
      " 'Home for the Holidays ' 'Mallrats ' 'Across the Sea of Time '\n",
      " 'Beautiful Girls ' 'Leave It to Beaver ']\n",
      "['Maltese Falcon, The ' 'Koyaanisqatsi ' 'Window to Paris ' 'Amateur '\n",
      " 'Colonel Chabert, Le ' 'Surviving the Game ' 'Jerky Boys, The '\n",
      " 'Pillow Book, The ' 'Tough and Deadly ' 'Gate of Heavenly Peace, The '\n",
      " 'Modern Affair, A ' 'French Kiss ' 'Pompatus of Love, The '\n",
      " 'Evening Star, The ' 'Adventures of Pinocchio, The '\n",
      " \"Don't Be a Menace to South Central While Drinking Your Juice in the Hood \"\n",
      " 'George of the Jungle ' 'Chasing Amy ' 'Man in the Iron Mask, The '\n",
      " 'Palmetto ' 'Metisse ']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-7f538e5559c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmae\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mf1_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mskm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresTrans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresTrans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mmae\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mskm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresTrans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresTrans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mrmse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mskm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresTrans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresTrans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msquared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[1;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m     \"\"\"\n\u001b[1;32m-> 1068\u001b[1;33m     return fbeta_score(y_true, y_pred, beta=1, labels=labels,\n\u001b[0m\u001b[0;32m   1069\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1190\u001b[0m     \"\"\"\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1192\u001b[1;33m     _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[0;32m   1193\u001b[0m                                                  \u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1461\u001b[1;33m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[0;32m   1462\u001b[0m                                     pos_label)\n\u001b[0;32m   1463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1272\u001b[0m                          str(average_options))\n\u001b[0;32m   1273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1274\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1275\u001b[0m     \u001b[1;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m     \u001b[1;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[0;32m     93\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3de2d02b11921545bf1816bc45552ddc366ed99bb60e73ad62fb9cbd6f53e5b0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}